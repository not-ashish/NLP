{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ashish_ashok_IHLT_LAB7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5KJb2u89tlg",
        "outputId": "fca56afe-e8ce-4b89-f7d7-732662ea95c6"
      },
      "source": [
        "#Spacy's algorithm\n",
        "import nltk\n",
        "import random, math, copy, os, string\n",
        "from scipy.stats import pearsonr\n",
        "from nltk.metrics import jaccard_distance\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet as wn  \n",
        "from nltk.corpus import wordnet_ic\n",
        "from nltk.wsd import lesk\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "import re\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import spacy\n",
        "nltk.download('wordnet')\n",
        "nltk.download('universal_tagset') \n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('wordnet_ic')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "!pip install svgling"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "Requirement already satisfied: svgling in /usr/local/lib/python3.7/dist-packages (0.3.1)\n",
            "Requirement already satisfied: svgwrite in /usr/local/lib/python3.7/dist-packages (from svgling) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vW27RTBb9yTP",
        "outputId": "cd052a73-c158-4895-d8d7-2478803d97cc"
      },
      "source": [
        "import pandas as pd\n",
        "dt = pd.read_csv('/content/drive/My Drive/content/drive/test-gold/STS.input.SMTeuroparl.txt',sep='\\t',header=None)\n",
        "dt['gs'] = pd.read_csv('/content/drive/My Drive/content/drive/test-gold/STS.gs.SMTeuroparl.txt',sep='\\t',header=None)\n",
        "dt = dt.rename(columns={0: 'ENT_A', 1: 'ENT_B'})\n",
        "print(dt.head())\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('words')"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               ENT_A  ...    gs\n",
            "0  The leaders have now been given a new chance a...  ...  4.50\n",
            "1  Amendment No 7 proposes certain changes in the...  ...  5.00\n",
            "2  Let me remind you that our allies include ferv...  ...  4.25\n",
            "3        The vote will take place today at 5.30 p.m.  ...  4.50\n",
            "4  The fishermen are inactive, tired and disappoi...  ...  5.00\n",
            "\n",
            "[5 rows x 3 columns]\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV3P2nn7blID"
      },
      "source": [
        "# dictionary of all the NEC in the sentences\n",
        "def get_NEC_dict(df_column):\n",
        "  d = dict()\n",
        "  for idxA, xA in enumerate(df_column): \n",
        "    sent = nlp(xA)\n",
        "    for s in sent.ents:\n",
        "      d[s.text] = s.label_\n",
        "  return d\n",
        "\n",
        "# replacing the words with their corresponding NEC\n",
        "# regex + previously made dictionary\n",
        "def get_NEC_REPL_sent(df_column, DICT):\n",
        "  l=[]\n",
        "  for sent in df_column:\n",
        "    rep = dict((re.escape(k), v) for k, v in DICT.items()) \n",
        "    pattern = re.compile(\"|\".join(rep.keys()))\n",
        "    textf = pattern.sub(lambda m: rep[re.escape(m.group(0))], sent)\n",
        "    l.append(textf)\n",
        "  return l\n",
        "\n",
        "#jaccard distance for wanted cols\n",
        "def get_jd(data_f, colA, colB,name):\n",
        "  data_f[name] = \"\"\n",
        "  for index in data_f.index:\n",
        "    data_f[name][index] = 1 - jaccard_distance(set(data_f[colA][index]), set(data_f[colB][index]))\n",
        "  return data_f\n",
        "\n",
        "def sent_word_set(df, col):\n",
        "  df[col+\"_tok\"] = df[col].apply(lambda x: nltk.sent_tokenize(x))\n",
        "  df[col+\"_tok\"] = df[col+\"_tok\"].apply(lambda x: nltk.word_tokenize(x[0]))\n",
        "  df[col+\"_tok\"] = df[col+\"_tok\"].apply(set)\n",
        "\n",
        "  return df"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWVFv2Akc4rI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec9ea957-e24c-42de-e9d6-caf4c2a08b7c"
      },
      "source": [
        "# Mapping the NEC to their words \n",
        "ent_a_dict = get_NEC_dict(dt['ENT_A'])\n",
        "ent_b_dict = get_NEC_dict(dt['ENT_B'])\n",
        "\n",
        "# Applying the replacement\n",
        "dt['ENT_A_REPL'] = get_NEC_REPL_sent(dt['ENT_A'],ent_a_dict)\n",
        "dt['ENT_B_REPL'] = get_NEC_REPL_sent(dt['ENT_B'],ent_b_dict)\n",
        "\n",
        "#sent / word tokenizing and making a set (FOR THE REPLACED SENTENCES)\n",
        "dt = sent_word_set(dt,'ENT_A_REPL')\n",
        "dt = sent_word_set(dt,'ENT_B_REPL')\n",
        "\n",
        "# same as above but for the original sentences \n",
        "dt = sent_word_set(dt,'ENT_A')\n",
        "dt = sent_word_set(dt,'ENT_B')\n",
        "\n",
        "# jaccard distance between the original sentence and the replaced sentence \n",
        "dt = get_jd(dt, 'ENT_A_tok','ENT_A_REPL_tok','JD_A_REPL')\n",
        "dt = get_jd(dt, 'ENT_B_tok','ENT_B_REPL_tok','JD_B_REPL')\n",
        "\n",
        "\n",
        "#jaccard ditance between NEC replaced sentences\n",
        "dt = get_jd(dt, 'ENT_A_REPL_tok','ENT_B_REPL_tok','JD_ORIG_REPL')\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smo5TQZW0_je",
        "outputId": "a25021f4-bf6c-4241-c1e5-90a4b2361dd1"
      },
      "source": [
        "# pearson with: NEC being replaced in the original sentence and Sent tokenize + Word tokenize\n",
        "round(pearsonr(dt['gs'], dt['JD_ORIG_REPL'])[0],2)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.33"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "na6AoaeMdLl0",
        "outputId": "bc3b5aae-4378-4dec-8445-065574944c93"
      },
      "source": [
        "dt.head()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ENT_A</th>\n",
              "      <th>ENT_B</th>\n",
              "      <th>gs</th>\n",
              "      <th>ENT_A_REPL</th>\n",
              "      <th>ENT_B_REPL</th>\n",
              "      <th>ENT_A_REPL_tok</th>\n",
              "      <th>ENT_B_REPL_tok</th>\n",
              "      <th>ENT_A_tok</th>\n",
              "      <th>ENT_B_tok</th>\n",
              "      <th>JD_A_REPL</th>\n",
              "      <th>JD_B_REPL</th>\n",
              "      <th>JD_ORIG_REPL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The leaders have now been given a new chance a...</td>\n",
              "      <td>The leaders benefit aujourd' hui of a new luck...</td>\n",
              "      <td>4.50</td>\n",
              "      <td>The leaders have now been given a new chance a...</td>\n",
              "      <td>The leaders benefit aujourd' hui of a new luck...</td>\n",
              "      <td>{us, they, have, chance, ., been, let, The, no...</td>\n",
              "      <td>{of, them, ., ', luck, let, aujourd, The, ther...</td>\n",
              "      <td>{us, they, have, chance, ., been, let, The, no...</td>\n",
              "      <td>{of, them, ., ', luck, let, aujourd, The, ther...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.346154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Amendment No 7 proposes certain changes in the...</td>\n",
              "      <td>Amendment No 7 is proposing certain changes in...</td>\n",
              "      <td>5.00</td>\n",
              "      <td>Amendment No 7 proposes certain changes in the...</td>\n",
              "      <td>Amendment No CARDINAL is proposing certain cha...</td>\n",
              "      <td>{changes, Amendment, 7, certain, ., in, the, r...</td>\n",
              "      <td>{changes, Amendment, ., in, the, references, p...</td>\n",
              "      <td>{changes, Amendment, 7, certain, ., in, the, r...</td>\n",
              "      <td>{changes, Amendment, 7, ., in, the, references...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Let me remind you that our allies include ferv...</td>\n",
              "      <td>I would like to remind you that among our alli...</td>\n",
              "      <td>4.25</td>\n",
              "      <td>Let me remind you that our allies include ferv...</td>\n",
              "      <td>I would like to remind you that among our alli...</td>\n",
              "      <td>{remind, of, our, allies, ., me, include, that...</td>\n",
              "      <td>{you, of, among, would, our, allies, are, I, s...</td>\n",
              "      <td>{remind, of, our, allies, ., me, include, that...</td>\n",
              "      <td>{you, of, among, would, our, allies, are, I, s...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.391304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The vote will take place today at 5.30 p.m.</td>\n",
              "      <td>The vote will take place at 5.30pm</td>\n",
              "      <td>4.50</td>\n",
              "      <td>The vote will take place DATE at TIME</td>\n",
              "      <td>The vote will take place at CARDINAL</td>\n",
              "      <td>{take, vote, DATE, at, will, The, place, TIME}</td>\n",
              "      <td>{take, vote, at, will, The, place, CARDINAL}</td>\n",
              "      <td>{take, vote, today, ., at, 5.30, will, The, pl...</td>\n",
              "      <td>{take, vote, 5.30pm, at, will, The, place}</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The fishermen are inactive, tired and disappoi...</td>\n",
              "      <td>The fishermen are inactive, tired and disappoi...</td>\n",
              "      <td>5.00</td>\n",
              "      <td>The fishermen are inactive, tired and disappoi...</td>\n",
              "      <td>The fishermen are inactive, tired and disappoi...</td>\n",
              "      <td>{fishermen, ., are, disappointed, The, and, ti...</td>\n",
              "      <td>{fishermen, ., are, disappointed, The, and, ti...</td>\n",
              "      <td>{fishermen, ., are, disappointed, The, and, ti...</td>\n",
              "      <td>{fishermen, ., are, disappointed, The, and, ti...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               ENT_A  ... JD_ORIG_REPL\n",
              "0  The leaders have now been given a new chance a...  ...     0.346154\n",
              "1  Amendment No 7 proposes certain changes in the...  ...     0.666667\n",
              "2  Let me remind you that our allies include ferv...  ...     0.391304\n",
              "3        The vote will take place today at 5.30 p.m.  ...     0.666667\n",
              "4  The fishermen are inactive, tired and disappoi...  ...            1\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1O8ovfs0qqr"
      },
      "source": [
        "Conclusion: By looking at the above table we can conclude that compared to previous algorithms this has given a pearson of 0.33 as compared to senses which was 0.43\n",
        "\n",
        "Prior to this a dictionary was created and replaced with the word, however, not all occurences of the word were replaced. This is why using RegEx, we were able to replace all instances of the corresponding NEC-Word pairs. \n",
        "\n",
        "Overall, NEC is an interesting method to compare sentences but it would highly depend on the type of context the corpus comes from. As seen in this laboratory, and compared to the previous ones it would not be the first choice as the jaccard distances fluctuate too much between original sentence and NEC replaced sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "500ApZl91kQl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}